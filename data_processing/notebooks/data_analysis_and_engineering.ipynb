{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03793a-600f-4794-b6b2-113acb28f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebok loads & explores the dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8daaf-7eba-4d84-8c04-f404cbd65930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "from data_processing.utils import viewer\n",
    "import pathlib\n",
    "import trimesh\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa74bfe-1da4-4ff7-80ac-2482d27412fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656002b6-3577-4761-ae6d-81c0a9d99b92",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f9ca2-df98-49f5-a0b6-cb9dd367ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load global config.\n",
    "config_file = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f9432-b4fa-4cbd-acbf-a1766bbca9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_path = pathlib.Path(config_file.config['dataset']['train'])\n",
    "dataset_test_path = pathlib.Path(config_file.config['dataset']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351762e-6263-4da0-96d6-de6dd4355a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with class names & their indices.\n",
    "folders = [dir.stem for dir in sorted(dataset_train_path.iterdir()) if dir.is_dir()]\n",
    "classes = {folder: i for i, folder in enumerate(folders)};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd72d27-1543-4744-962e-1ba56e614dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486a2c2-5dc9-4391-890a-7ccb8187f713",
   "metadata": {},
   "source": [
    "# Visualize an example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e2dcd-3359-4383-9149-1245588a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = dataset_train_path / 'motor/00001173.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3acd0-ece3-4d12-9879-f23c5bca6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = trimesh.load(example_path, force='mesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218c354-18b1-4183-b8ab-df590e66fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viewer.Viewer()\n",
    "viz.add_mesh(example)\n",
    "viz.add_pc(example.vertices, size=2.5)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4f4fe-7418-40b6-be7b-4d4fb09c5822",
   "metadata": {},
   "source": [
    "# Normalize & augment the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd92ea-2ffa-4f42-9c97-950f68ffb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. All the augmentation functions had been written as Pytorch Dataset transformations!\n",
    "# Source: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84907db3-9a6e-464f-ac03-876c5e6f25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra points to the point clouds.\n",
    "# This step is done as the mesh vertices alone do not give enough spatial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf17ed1-5974-46f9-b613-a9199a78de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplePc(object):\n",
    "    def __init__(self, points: int = 1024):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            points: Number of points to sample from the mesh.\n",
    "        \"\"\"\n",
    "        self.points = points\n",
    "    def __call__(self, mesh: trimesh.Trimesh):\n",
    "        \"\"\"Samples the point cloud from the mesh surface.\n",
    "        \n",
    "        Args:\n",
    "            mesh: Input mesh.\n",
    "        Returns:\n",
    "            Sampled point cloud.\n",
    "        \"\"\"\n",
    "        pc_sampled, _ = trimesh.sample.sample_surface(mesh, self.points, seed=SEED)\n",
    "    \n",
    "        return pc_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c2ebf-f1d5-489f-9c01-7a5aee3dde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = SamplePc()(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d39ec-1f62-4dcf-bc26-7df278789239",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viewer.Viewer()\n",
    "viz.add_pc(pc, size=2.5)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a9d4a-281b-4ffc-8cec-aa129b9965ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizePc(object):\n",
    "    def __call__(self, pc:np.ndarray)-> np.ndarray:\n",
    "        # TODO(vice) Check the paper for name of the normalization\n",
    "        \"\"\"Normalizes point cloud.\n",
    "        \n",
    "        Args:\n",
    "            pc: Input point cloud.\n",
    "        \n",
    "        Returns:\n",
    "            Normalized point cloud.\n",
    "        \"\"\"\n",
    "        if len(pc.shape) != 2:\n",
    "            print('Invalid point cloud!')\n",
    "            return np.array([])\n",
    "        pc_norm = pc - np.mean(pc, axis=0)\n",
    "        pc_norm /= np.max(np.linalg.norm(pc_norm, axis=1))\n",
    "        \n",
    "        return pc_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890f1a8-1690-4ab9-bc29-cbd5bc408e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_norm = NormalizePc()(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7539bcc-4500-4927-b61c-225350ff889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viewer.Viewer()\n",
    "viz.add_pc(pc_norm, size=2.5)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe37d3-14f4-4a97-a285-ba12df3ff839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyRandomRotationZ(object):\n",
    "    def __call__(self, pc:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Applies random rotation around the z axis\n",
    "        to the input point cloud.\n",
    "    \n",
    "        Args:\n",
    "            pc: Input point cloud.\n",
    "    \n",
    "        Returns:\n",
    "            Rotated point cloud.\n",
    "        \"\"\"\n",
    "        theta = np.random.random(1) * 2 * math.pi\n",
    "        rot_matrix = np.array([[math.cos(theta), -math.sin(theta), 0],\n",
    "                               [math.sin(theta), math.cos(theta), 0],\n",
    "                               [0, 0, 1]])\n",
    "          \n",
    "        pc_rot = rot_matrix.dot(pc.T).T\n",
    "    \n",
    "        return pc_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99346cca-7173-4a58-af30-d703c6f57cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_rot = ApplyRandomRotationZ()(pc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15148f69-0ff1-4652-922d-bdaacba5e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viewer.Viewer()\n",
    "viz.add_pc(pc_rot, size=2.5)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa107030-86ae-44a3-963a-724b7791bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddJitter(object):\n",
    "    def __call__(self, pc:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Applied random jitter to the point cloud.\n",
    "    \n",
    "        Args:\n",
    "            pc: Input point cloud.\n",
    "    \n",
    "        Returns:\n",
    "            Point cloud with added noise.\n",
    "        \"\"\"\n",
    "        jitter = np.random.normal(0, 0.02, (pc.shape))\n",
    "        pc_noisy = pc + jitter\n",
    "        \n",
    "        return pc_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f38b65-1b0f-4d54-8c3c-aa1d3959e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_noisy = AddJitter()(pc_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7e9c5-535b-4b15-b29e-a91cf037c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viewer.Viewer()\n",
    "viz.add_pc(pc_noisy, size=2.5)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78a054-0268-40bd-8a9f-a20b08fbb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Union\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956015af-242d-4a9c-8571-89b6b84f2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transforms = transforms.Compose([\n",
    "                                SamplePc(1024),\n",
    "                                NormalizePc()\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6d606-a8cf-4c19-a5d8-66661a602c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1024 points per cloud as in the paper!\n",
    "train_transforms = transforms.Compose([\n",
    "                              SamplePc(1024),\n",
    "                              NormalizePc(),\n",
    "                              ApplyRandomRotationZ(),\n",
    "                              AddJitter()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e858c3a-8d7d-4396-af5c-2529bb05cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class McbData(Dataset):\n",
    "    def __init__(self, dataset_dir: Union[pathlib.Path, str],\n",
    "                 transforms = default_transforms):\n",
    "        \"\"\"Loads MCB dataset...\n",
    "        \n",
    "        Args:\n",
    "            dataset_dir: Input directory.\n",
    "        \"\"\"\n",
    "        self.dataset_dir = pathlib.Path(dataset_dir)\n",
    "        # Create a dict with class names & their indices.\n",
    "        folders = [dir.stem for dir in sorted(dataset_train_path.iterdir()) if dir.is_dir()]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)};\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        # Load all the samples paths and their category idx.\n",
    "        self.samples = []\n",
    "        for category, category_idx in self.classes.items():\n",
    "            cat_dir = self.dataset_dir/pathlib.Path(category)\n",
    "            for mesh in cat_dir.iterdir():\n",
    "                if mesh.is_file() and mesh.suffix == '.obj':\n",
    "                    sample = {}\n",
    "                    sample['mesh_path'] = mesh.absolute()\n",
    "                    sample['category_idx'] = category_idx\n",
    "                    self.samples.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file):\n",
    "        verts, faces = read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms((verts, faces))\n",
    "        return pointcloud\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"Returns an single entry of the dataset which consists of input point\n",
    "        cloud and the output category.\n",
    "    \n",
    "        Args:\n",
    "            idx: Index of the entry.\n",
    "    \n",
    "        Returns:\n",
    "            Tuple containing dataset entry.\n",
    "        \"\"\"\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "               'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bd6f2-4031-48a0-ab0e-432956f2c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "McbData(dataset_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906ae52-dbb6-42ab-84e6-b4db14c48807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theia_pointnet",
   "language": "python",
   "name": "theia_pointnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
