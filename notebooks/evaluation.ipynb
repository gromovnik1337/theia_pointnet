{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03793a-600f-4794-b6b2-113acb28f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluation of PointNet Classification model trained on MCB B dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8daaf-7eba-4d84-8c04-f404cbd65930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "from config import config\n",
    "from typing import List\n",
    "from typing import Union\n",
    "from typing import Any\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from model.model import PointNetClassification\n",
    "from utils import viewer\n",
    "import model.dataset as dataset\n",
    "from torchvision import transforms\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa74bfe-1da4-4ff7-80ac-2482d27412fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(\n",
    "    model_name: str, train_loss: List[float], valid_loss: List[float]\n",
    ") -> None:\n",
    "    \"\"\"Visualizes the loss data of the trained model.\n",
    "\n",
    "    Args:\n",
    "        model_name: Name of the trained model.\n",
    "        train_loss: Loss data generated during training.\n",
    "        valid_loss: Loss data generated during validation.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.suptitle(model_name + \" loss values\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(valid_loss)\n",
    "    plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7926081c-03e2-4aaa-987c-d770b7ab17e4",
   "metadata": {},
   "source": [
    "# Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24ffde-020a-4897-b58e-049a42f877a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = \"/media/gromovnik/Vice_SSD/01. Projects/01. THEIA/theia_pointnet/model/trained_models/mcb_2.pt\"\n",
    "TRAIN_LOSS_PATH = \"/media/gromovnik/Vice_SSD/01. Projects/01. THEIA/theia_pointnet/model/trained_models/mcb_2_training_loss.txt\"\n",
    "VALID_LOSS_PATH = \"/media/gromovnik/Vice_SSD/01. Projects/01. THEIA/theia_pointnet/model/trained_models/mcb_2_validation_loss.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae8a73-fc76-47ce-b351-38e2d2f16b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_list(input_path: Union[pathlib.Path, str]) -> List[str]:\n",
    "    \"\"\"Loads a .txt file into a list.\n",
    "    Args:\n",
    "        input_path: Input path to the txt file.\n",
    "\n",
    "    Returns:\n",
    "        List containing data from the .txt file.\n",
    "    \"\"\"\n",
    "    with open(input_path, \"r\") as f:\n",
    "        data = f.read().splitlines()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839be078-002e-47e8-8f28-8a5984fbae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = pathlib.Path(TRAINED_MODEL_PATH).stem\n",
    "train_loss= txt_to_list(TRAIN_LOSS_PATH)\n",
    "valid_loss= txt_to_list(VALID_LOSS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b75fcd-b724-4edc-8a9d-0dccfbb59326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert str to float & tidy up.\n",
    "train_loss = [float(el) for el in train_loss]\n",
    "train_loss = [round(el, 4) for el in train_loss]\n",
    "\n",
    "valid_loss = [float(el) for el in valid_loss]\n",
    "valid_loss = [round(el, 4) for el in valid_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b375bd-c31b-4a7f-b914-3526ff7404d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model_name, train_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656002b6-3577-4761-ae6d-81c0a9d99b92",
   "metadata": {},
   "source": [
    "# Load the model & evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb15b08-b6a7-49f2-ab77-4dfef00f557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_STATE_DICT_PATH = \"/media/gromovnik/Vice_SSD/01. Projects/01. THEIA/theia_pointnet/model/trained_models/mcb_2_state_dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f9ca2-df98-49f5-a0b6-cb9dd367ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load global config.\n",
    "config_file = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d2363-0e0f-447e-9161-dd5ade0a5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device & clean the memory\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a587e8d-e60b-4660-b160-322071df6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model object & test dataset.\n",
    "dataset_test_path = pathlib.Path(config_file.config[\"dataset\"][\"test\"])\n",
    "batch_size = config_file.config[\"batch_size\"]\n",
    "test_transforms = transforms.Compose([dataset.NormalizePc()])\n",
    "dataset_test = dataset.McbData(dataset_test_path, test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset_test, batch_size=batch_size, shuffle=False\n",
    "    ) # If shuffle is True, plotting is much harder as point clouds have to kept in memory.\n",
    "\n",
    "learning_rate = config_file.config[\"lr\"]\n",
    "point_net = PointNetClassification(len(dataset_test.classes), learning_rate)\n",
    "point_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8eff70-9356-4d9a-95f6-f351aca44e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model.\n",
    "# GPU.\n",
    "point_net.load_state_dict(torch.load(TRAINED_STATE_DICT_PATH))\n",
    "\n",
    "# CPU.\n",
    "#point_net.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/point_net/pre_trained_classification.pth', map_location=torch.device('cpu')))\n",
    "point_net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e9708-a376-45c6-ad19-ea253db68dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform inference on a whole test dataset.\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data_idx, data in enumerate(test_loader):\n",
    "        print('Batch [%4d / %4d]' % (data_idx+1, len(test_loader)))\n",
    "        inputs = data[\"pc\"].to(device).float()\n",
    "        labels = data[\"category_idx\"].to(device)\n",
    "                 \n",
    "        outputs, __, __ = point_net(inputs.transpose(1, 2))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds += list(preds.cpu().numpy())\n",
    "        all_labels += list(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f501a-498e-4a88-94eb-480bc5f696ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results for a single dataset element.\n",
    "n_sample = 2705\n",
    "print(\"Sample: \", n_sample)\n",
    "print(\"Point cloud: \")\n",
    "print(dataset_test[n_sample]['pc'])\n",
    "print(\"Predicted label: \", list(dataset_test.classes.keys())[all_preds[n_sample]])\n",
    "print(\"True label: \", list(dataset_test.classes.keys())[all_labels[n_sample]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd2d83-d559-4ddb-83ea-d13a3e4a5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viewer.Viewer()\n",
    "viz.add_pc(dataset_test[n_sample]['pc'], size=2.5)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0915ae0-90cc-4699-a29d-7fbbfa329f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & visualize confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ae811-7106-4cef-b0cb-f441e0df6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm: np.ndarray, classes: List[str], normalize: bool = False,\n",
    "                          title: str = 'Confusion matrix',\n",
    "                          cmap: matplotlib.colors.LinearSegmentedColormap = plt.cm.Blues):\n",
    "    \"\"\"Visualizes confusion matrix.\n",
    "    Source: https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "\n",
    "    Args:\n",
    "        cm: Confussion matrix.\n",
    "        classes: List of classes.\n",
    "        normalize: If true, confusion matrix will be normalized.\n",
    "        title: Title of the plotted matrix.\n",
    "        cmap: Used color map.\n",
    "    \"\"\"\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e054ab-695b-4ee9-9cc7-1175a4ea7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fae2b-b90e-42b8-b28e-1a08ef443adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot_confusion_matrix(cm, list(dataset_test.classes.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a9404-e71a-4783-9cd6-800c268a21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute F1 score.\n",
    "f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6a795b-5fe4-48e1-857a-d6be31eb70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IoU.\n",
    "iou = jaccard_score(all_labels, all_preds, average='micro')\n",
    "iou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theia_pointnet",
   "language": "python",
   "name": "theia_pointnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
